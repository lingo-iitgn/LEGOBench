{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml\n",
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=pd.read_pickle(\"/home/harsh.d/Shoaib/arxiv_metadata/metadata_ids.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th>authors_tup</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>structadmm: a systematic, high-efficiency framework of structured weight pruning for dnns</th>\n",
       "      <th>(t zhang, s ye, k zhang, x ma, n liu, l zhang, j tang, k ma, x lin, m fardad, y wang)</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distributed optimization and statistical learning via the alternating direction method of multipliers</th>\n",
       "      <th>([ references, boyd)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning both weights and connections for efficient neural network</th>\n",
       "      <th>()</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convergence analysis of alternating direction method of multipliers for a family of nonconvex problems</th>\n",
       "      <th>(m luo, z hong, ; luo, hong)</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning structured sparsity in deep neural networks</th>\n",
       "      <th>()</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1-depth revisited: a robust angle-based outlier factor in high-dimensional space</th>\n",
       "      <th>(n pham,)</th>\n",
       "      <td>62841251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>locality adaptive discriminant analysis framework</th>\n",
       "      <th>(x li, q wang, f nie, m chen)</th>\n",
       "      <td>62841252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear discriminant analysis: new formulations and overfit analysis</th>\n",
       "      <th>(d luo, c ding, h huang)</th>\n",
       "      <td>62841254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robust 2dpca with non-greedy ¡inline-formula¿ ¡tex-math notation=\"latex\"¿ 1 ¡/tex-math¿¡/inline-formula¿-norm maximization for image analysis</th>\n",
       "      <th>(r wang, f nie, x yang, f gao, m yao)</th>\n",
       "      <td>62841259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generalization bounds for supervised dimensionality reduction</th>\n",
       "      <th>(m mohri, a rostamizadeh, d storcheus)</th>\n",
       "      <td>62841279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19072607 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                             id\n",
       "title                                              authors_tup                                                 \n",
       "structadmm: a systematic, high-efficiency frame... (t zhang, s ye, k zhang, x ma, n liu, l zhang, ...         0\n",
       "distributed optimization and statistical learni... ([ references, boyd)                                       1\n",
       "learning both weights and connections for effic... ()                                                         2\n",
       "convergence analysis of alternating direction m... (m luo, z hong, ; luo, hong)                               3\n",
       "learning structured sparsity in deep neural net... ()                                                         4\n",
       "...                                                                                                         ...\n",
       "l1-depth revisited: a robust angle-based outlie... (n pham,)                                           62841251\n",
       "locality adaptive discriminant analysis framework  (x li, q wang, f nie, m chen)                       62841252\n",
       "linear discriminant analysis: new formulations ... (d luo, c ding, h huang)                            62841254\n",
       "robust 2dpca with non-greedy ¡inline-formula¿ ¡... (r wang, f nie, x yang, f gao, m yao)               62841259\n",
       "generalization bounds for supervised dimensiona... (m mohri, a rostamizadeh, d storcheus)              62841279\n",
       "\n",
       "[19072607 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper ID - Reference ID mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dataframe to dictionary\n",
    "temp=temp.to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_file_new = glob.glob(\"/home/harsh.d/arxiv/xml_new/*\")\n",
    "xml_file_old = glob.glob(\"/home/harsh.d/old_xml_files/*\")\n",
    "xml_files = xml_file_old + xml_file_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap_df=pd.read_json(\"/home/harsh.d/Shoaib/arxiv_metadata/arxiv-metadata-oai-snapshot.json\",lines=True)\n",
    "snap_df['id']=snap_df['id'].str.replace('/','')\n",
    "snap_df['title']=snap_df['title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get Data with Citation-Reference Mapping\"\"\"\n",
    "\n",
    "def get_data(file):\n",
    "    \n",
    "    data={}\n",
    "    names=[]\n",
    "\n",
    "    # Read XML\n",
    "    with codecs.open(file,'r',\"utf-8\") as tei:\n",
    "        soup = BeautifulSoup(tei, 'lxml')\n",
    "\n",
    "    # Paper Title ID \n",
    "    title=soup.teiheader.title.get_text().lower()\n",
    "    if(title==''):\n",
    "        title=snap_df[snap_df['id']==file.split('/')[-1][:-8]]['title'].values[0].lower()\n",
    "\n",
    "    # Paper Author Details    \n",
    "    for author in soup.teiheader.find_all('author'):\n",
    "\n",
    "        if(author.find('persname')!=None):\n",
    "\n",
    "            if(author.find('persname').forename!=None and author.find('persname').surname!=None):\n",
    "                names.append(author.find('persname').forename.get_text()[0].lower()+\" \"+author.find('persname').surname.get_text().lower())\n",
    "\n",
    "            elif(author.find('persname').forename==None):\n",
    "                names.append(author.find('persname').surname.get_text().lower())\n",
    "\n",
    "            else:\n",
    "                names.append(author.find('persname').forename.get_text()[0].lower())\n",
    "    \n",
    "    try:\n",
    "        paper_id=temp[(title,tuple(names))]['id']\n",
    "    except:\n",
    "        paper_id=''\n",
    "                \n",
    "    # Dictionary containg <XML ID: Citation> format\n",
    "    citations={}\n",
    "    for targets in soup.find_all('ref'):\n",
    "        if(targets.get('type')=='bibr' and targets.get('target')!=None):\n",
    "            citations[targets.get('target')]=targets.get_text().lower()\n",
    "    \n",
    "    # Extract Citation, Reference Titles, Reference Authors \n",
    "    for ref in soup.back.find_all('biblstruct'):\n",
    "        \n",
    "        if('#'+ref.get(\"xml:id\") in citations):\n",
    "            \n",
    "            cit=citations['#'+ref.get(\"xml:id\")]\n",
    "            \n",
    "#             xml_id=ref.get(\"xml:id\")\n",
    "            \n",
    "            for t in ref.find_all('title'):\n",
    "                if(t.get_text()!=''):\n",
    "                    ref_title=t.get_text().lower()\n",
    "                    break\n",
    "            \n",
    "#             if(ref.find(type=\"arXiv\")!=None):\n",
    "#                 ref_doi=ref.find(type=\"arXiv\").get_text().lower()\n",
    "#             elif(ref.find(type=\"DOI\")!=None):\n",
    "#                 ref_doi=ref.find(type=\"DOI\").get_text().lower()\n",
    "#             else:\n",
    "#                 ref_doi=''\n",
    "            \n",
    "            ref_authors=[]\n",
    "            for author in ref.find_all('author'):\n",
    "\n",
    "                if(author.find('persname')!=None):\n",
    "\n",
    "                    if(author.find('persname').forename!=None and author.find('persname').surname!=None):\n",
    "                        ref_authors.append(author.find('persname').forename.get_text()[0].lower()+\" \"+author.find('persname').surname.get_text().lower())\n",
    "\n",
    "                    elif(author.find('persname').forename==None):\n",
    "                        ref_authors.append(author.find('persname').surname.get_text().lower())\n",
    "\n",
    "                    else:\n",
    "                        ref_authors.append(author.find('persname').forename.get_text()[0].lower())\n",
    "                        \n",
    "#             titles.append(ref_title)\n",
    "#             authors.append(ref_authors)\n",
    "#             doi.append(ref_doi)\n",
    "            try:\n",
    "                ref_paper_id=temp[(ref_title,tuple(ref_authors))]['id']\n",
    "            except:\n",
    "                ref_paper_id=''\n",
    "        \n",
    "#             data[xml_id]={\n",
    "#               'citation':cit,\n",
    "#               'reference':ref_title,\n",
    "#               'authors':ref_authors\n",
    "#             }\n",
    "\n",
    "            data[cit]=ref_paper_id\n",
    "            \n",
    "        \n",
    "    return file.split('/')[-1],paper_id,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1beb1b3da4c04f67842824d9d1d74d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3973cdfe302e45eaa0cf9ed34aa93a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "mapping_outputs=[]\n",
    "\n",
    "def driver_func():\n",
    "    \n",
    "    # Note: Keep Num_Process <= 60 to avoid system hang\n",
    "    PROCESSES = 40\n",
    "    \n",
    "    with multiprocessing.Pool(PROCESSES) as pool:\n",
    "        results=[pool.apply_async(get_data, args=(p,)) for p in tqdm(xml_files[:100000])]\n",
    "         \n",
    "        for r in tqdm(results):\n",
    "            try:\n",
    "                if(r.get(timeout=5)!=None):\n",
    "                    mapping_outputs.append(r.get())\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "driver_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd1a9e2dd8f410ea89e4e295aba3e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=142301.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3366320f2f02476d8dce0af60b3cf8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=142301.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "mapping_outputs=[]\n",
    "\n",
    "def driver_func():\n",
    "    \n",
    "    # Note: Keep Num_Process <= 60 to avoid system hang\n",
    "    PROCESSES = 40\n",
    "    \n",
    "    with multiprocessing.Pool(PROCESSES) as pool:\n",
    "        results=[pool.apply_async(get_data, args=(p,)) for p in tqdm(xml_files)]\n",
    "         \n",
    "        for r in tqdm(results):\n",
    "            try:\n",
    "                if(r.get(timeout=5)!=None):\n",
    "                    mapping_outputs.append(r.get())\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "driver_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "cit_ref=pd.DataFrame(mapping_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1807.11091.tei.xml</td>\n",
       "      <td>0</td>\n",
       "      <td>{'[boyd et al., 2011;': 1, 'han et al., 2016]'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hep-ph0003173.tei.xml</td>\n",
       "      <td>6</td>\n",
       "      <td>{'[1]': 7, '2': 8, '[3]': 9, '[5]': 10, '[6]':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002.06870.tei.xml</td>\n",
       "      <td>22</td>\n",
       "      <td>{'(1)': 23, '(2)': 24, '(3)': 25, '[4,': 26, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1204.6600.tei.xml</td>\n",
       "      <td>45</td>\n",
       "      <td>{'[1]': 46, '[2]': 47, '[3]': 48, '[4]': 49, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1404.3331.tei.xml</td>\n",
       "      <td>99</td>\n",
       "      <td>{', aldous, 1985': 100, ', bertoin, 2006': 101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940483</th>\n",
       "      <td>2011.02495.tei.xml</td>\n",
       "      <td>62841089</td>\n",
       "      <td>{'abbott et al. 2009': 856898, '(becker 2015)'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940484</th>\n",
       "      <td>2101.06890.tei.xml</td>\n",
       "      <td>52360140</td>\n",
       "      <td>{'[1]': 2977897, '[2,': 6792658, '[3]': 628411...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940485</th>\n",
       "      <td>2112.01060.tei.xml</td>\n",
       "      <td>62841141</td>\n",
       "      <td>{'[2]': 62841142, '[3]': 2259011, '[4,': 21118...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940486</th>\n",
       "      <td>2106.06977.tei.xml</td>\n",
       "      <td>62841167</td>\n",
       "      <td>{'[1]': 10882, '[2]': 146279, '[3]': 4296414, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940487</th>\n",
       "      <td>2202.04678.tei.xml</td>\n",
       "      <td>62841235</td>\n",
       "      <td>{'1': 8192405, '[2]': 149452, '3': 62841238, '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1940488 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0         1  \\\n",
       "0           1807.11091.tei.xml         0   \n",
       "1        hep-ph0003173.tei.xml         6   \n",
       "2           2002.06870.tei.xml        22   \n",
       "3            1204.6600.tei.xml        45   \n",
       "4            1404.3331.tei.xml        99   \n",
       "...                        ...       ...   \n",
       "1940483     2011.02495.tei.xml  62841089   \n",
       "1940484     2101.06890.tei.xml  52360140   \n",
       "1940485     2112.01060.tei.xml  62841141   \n",
       "1940486     2106.06977.tei.xml  62841167   \n",
       "1940487     2202.04678.tei.xml  62841235   \n",
       "\n",
       "                                                         2  \n",
       "0        {'[boyd et al., 2011;': 1, 'han et al., 2016]'...  \n",
       "1        {'[1]': 7, '2': 8, '[3]': 9, '[5]': 10, '[6]':...  \n",
       "2        {'(1)': 23, '(2)': 24, '(3)': 25, '[4,': 26, '...  \n",
       "3        {'[1]': 46, '[2]': 47, '[3]': 48, '[4]': 49, '...  \n",
       "4        {', aldous, 1985': 100, ', bertoin, 2006': 101...  \n",
       "...                                                    ...  \n",
       "1940483  {'abbott et al. 2009': 856898, '(becker 2015)'...  \n",
       "1940484  {'[1]': 2977897, '[2,': 6792658, '[3]': 628411...  \n",
       "1940485  {'[2]': 62841142, '[3]': 2259011, '[4,': 21118...  \n",
       "1940486  {'[1]': 10882, '[2]': 146279, '[3]': 4296414, ...  \n",
       "1940487  {'1': 8192405, '[2]': 149452, '3': 62841238, '...  \n",
       "\n",
       "[1940488 rows x 3 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cit_ref"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv] *",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
